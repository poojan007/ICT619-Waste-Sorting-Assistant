{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJkscNMhfCZrUs2hUpYNjC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojan007/ICT619-Waste-Sorting-Assistant/blob/main/ICT619_Assignment_1_Data_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SmartSort Model\n",
        "This model provides outlines a process for loading augmenting, and training a convolutional neural network (CNN) on image data for a binary classification task.\n",
        "\n"
      ],
      "metadata": {
        "id": "b0ShL6qcvVyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload file by mounting Google Drive"
      ],
      "metadata": {
        "id": "yyFnzHmt5YkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/mntDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtf-pm3_5cXD",
        "outputId": "958444e5-861b-4271-91bc-77f9c15a2a88"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /mntDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data from google drive and unzip it\n",
        "\n",
        "!unzip -q /mntDrive/MyDrive/ICT619-Dataset/archive.zip -d data"
      ],
      "metadata": {
        "id": "U5e-U7Q854uZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "QvVnE9s_5XGU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p9tM2Dzlm_PO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define dataset paths"
      ],
      "metadata": {
        "id": "jpts8eGZwFpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/data/DATASET/TRAIN'\n",
        "validation_dir = '/content/data/DATASET/TEST'"
      ],
      "metadata": {
        "id": "XMkE9NhgwIyU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation\n",
        "\n",
        "A data augmentation pipeline is created using a 'Sequential' model, which includes random flips, rotations, zooms, and translations. This is to artifically expland the training dataset by generating modifiied versions of the training images, helping the model generalize better."
      ],
      "metadata": {
        "id": "6hAu5T0O14wK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "  layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "  layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0.2)\n",
        "])\n"
      ],
      "metadata": {
        "id": "GFWIa-xe2OUp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the datasets\n",
        "\n",
        "The training and validation datasets are loaded from directories, specifying image size, batch size, and how the data is split. The 'validation_split' parameter"
      ],
      "metadata": {
        "id": "JzbNRgaF2XyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ5Xypwg2vnj",
        "outputId": "c541531d-db76-4dee-afc2-3574f29ae762"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22564 files belonging to 2 classes.\n",
            "Using 18052 files for training.\n",
            "Found 2513 files belonging to 2 classes.\n",
            "Using 502 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring Datasets for Performance\n",
        "\n",
        "These lines configure the datasets for performance '.cache()' keeps the images in memory after they're loaded off disk during the first epoch, '.shuffle()' randamizes the order of the images to reduce model overfitting, and '.prefetch()' overlaps data preprocessing and model execution while training."
      ],
      "metadata": {
        "id": "aCIdLLMr20IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "hWy-njOM3Kas"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building\n",
        "\n",
        "Building the CNN model architecture. It starts with the data augmentation layer, followed by a rescaling layer to normalize pixel values. Then, it adds convolutional and max pooling layers for feature extraction, followed by dense layers for classification. The final layer uses a sigmoid activation function suitable for binary classification."
      ],
      "metadata": {
        "id": "Y9uKJDJ23Nt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    data_augmentation,\n",
        "    layers.experimental.preprocessing.Rescaling(1./255),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "cNYPKyoc3ltm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the Model\n",
        "\n",
        "The model is compiled with the Adam optimizer and binary crossentropy loss function, which is appropriate for binary classification tasks. The model's performance will be evaluated based on accuracy."
      ],
      "metadata": {
        "id": "C_PhT4yh3n5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fp2XR0XP35ez"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training\n",
        "\n",
        "Finally, the model is trained for a defined number of epochs using the training dataset, with validation performed on the validation dataset. The 'fit' method returns a history object containing training and validation loss and accuracy for each epoch, which can be used for analysis of the model's performance over time."
      ],
      "metadata": {
        "id": "yFVQGOmn36tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO0k4CAy4QPh",
        "outputId": "3366f8f9-e5c8-4b6a-c459-c76c030ad231"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "565/565 [==============================] - 950s 2s/step - loss: 0.6780 - accuracy: 0.7816 - val_loss: 0.3716 - val_accuracy: 0.8645\n",
            "Epoch 2/10\n",
            "565/565 [==============================] - 900s 2s/step - loss: 0.4450 - accuracy: 0.8048 - val_loss: 0.3531 - val_accuracy: 0.8685\n",
            "Epoch 3/10\n",
            "565/565 [==============================] - 904s 2s/step - loss: 0.4407 - accuracy: 0.8050 - val_loss: 0.3249 - val_accuracy: 0.8845\n",
            "Epoch 4/10\n",
            "565/565 [==============================] - 910s 2s/step - loss: 0.4392 - accuracy: 0.8069 - val_loss: 0.2910 - val_accuracy: 0.8944\n",
            "Epoch 5/10\n",
            "565/565 [==============================] - 902s 2s/step - loss: 0.4276 - accuracy: 0.8140 - val_loss: 0.3580 - val_accuracy: 0.8924\n",
            "Epoch 6/10\n",
            "565/565 [==============================] - 899s 2s/step - loss: 0.4286 - accuracy: 0.8047 - val_loss: 0.3312 - val_accuracy: 0.9044\n",
            "Epoch 7/10\n",
            "565/565 [==============================] - 925s 2s/step - loss: 0.4212 - accuracy: 0.8177 - val_loss: 0.3131 - val_accuracy: 0.9084\n",
            "Epoch 8/10\n",
            "565/565 [==============================] - 892s 2s/step - loss: 0.4218 - accuracy: 0.8181 - val_loss: 0.3046 - val_accuracy: 0.8984\n",
            "Epoch 9/10\n",
            "565/565 [==============================] - 890s 2s/step - loss: 0.4181 - accuracy: 0.8193 - val_loss: 0.3164 - val_accuracy: 0.8964\n",
            "Epoch 10/10\n",
            "565/565 [==============================] - 899s 2s/step - loss: 0.4130 - accuracy: 0.8176 - val_loss: 0.3179 - val_accuracy: 0.9064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the performance"
      ],
      "metadata": {
        "id": "QWJvGhyw8tLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(train_ds, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(val_ds, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "id": "Rt281bzW8RJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing training results\n",
        "\n",
        "The plots of loss and accuracy on the training and validation sets."
      ],
      "metadata": {
        "id": "MU4PlMT78zc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "metadata": {
        "id": "kImfrzdh83dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validating the model"
      ],
      "metadata": {
        "id": "Io40dKa14hp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prepare and predict the class of an image\n",
        "def predict_with_augmentation(img_path, model):\n",
        "    # Load the image\n",
        "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Expand dimensions to match the shape of model input\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Predict (data augmentation is applied automatically)\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # Assuming binary classification with a sigmoid activation, adjust if necessary\n",
        "    predicted_class = 'Recyclable Waste' if prediction[0] == 1 else 'Organic Waste'\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "# Example usage\n",
        "img_path = '/plastic1.jpg'\n",
        "predicted_class = predict_with_augmentation(img_path, model)\n",
        "print(f'Predicted: {predicted_class}')"
      ],
      "metadata": {
        "id": "vyb7Ycvq4kwV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}